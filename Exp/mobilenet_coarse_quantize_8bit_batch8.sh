nnfusion mobilenet_coarse_batch8.onnx  -f onnx  -fblockfusion_level=0 -fquantize_cfg mobilenet_coarse_quantize_cfg_batch8 -fbatchnorm_inference_folding=false
