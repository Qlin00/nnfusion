nnfusion mobilenet_coarse0.6_batch8.onnx  -f onnx  -fblockfusion_level=0 -fquantize_cfg mobilenet_coarse0.6_quantize_cfg_batch8 -fbatchnorm_inference_folding=false
