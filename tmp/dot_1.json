[
    {
        "tvm_func_name": "MatrixMulCUDA_8bit",
        "op_type": "QuantizeDot",
        "parameters": {
            "arg0_shape": [
                256,
                256
            ],
            "arg1_shape": [
                256,
                256
            ],
            "arg2_shape": [
                256,
                256
            ],
            "arg3_shape": [
                256,
                256
            ],
            "arg4_shape": [
                256,
                256
            ],
            "arg5_shape": [
                1
            ],
            "arg6_shape": [
                1
            ],
            "out_shape": [
                256,
                256
            ],
            "transpose_A": false,
            "transpose_B": false,
            "in_quantize_bit": 8,
            "out_quantize_bit": 8
        },
        "code": "extern \"C\" __global__ void MatrixMulCUDA_8bit(float *fA, float *fW, float *fMulti_w_zp, float *fW_zp, float *fZP_accu, float * finteger, float * fshift_val, float *fC){\n    /*Prepare Stage*/\n    // set the block size and matrix size constants here\n    const int BLOCK_SIZE=32;\n    const int k=256, n=256;\n    // convert the input pointer to the correct type\n    uint8_t * W =  reinterpret_cast<uint8_t*>(fW);\n    uint8_t * A =  reinterpret_cast<uint8_t*>(fA);\n    uint8_t * C =  reinterpret_cast<uint8_t*>(fC);\n    unsigned int * Multi_w_zp =  reinterpret_cast<unsigned int *>(fMulti_w_zp);\n    uint8_t * W_zp =  reinterpret_cast<uint8_t *>(fW_zp);\n    unsigned int * ZP_accu =  reinterpret_cast<unsigned int *>(fZP_accu);\n    const int shift_val = (int)(*fshift_val);\n    const int integer = (int)(*finteger);\n\n\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    int aBegin = BLOCK_SIZE * by * k;\n    int aEnd = aBegin + k - 1;\n\n    int bBegin = BLOCK_SIZE * bx * k;\n\n    __shared__ uint8_t As[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ uint8_t Bs[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ uint8_t Wzp[BLOCK_SIZE][BLOCK_SIZE];\n\n    unsigned int cSub = 0;\n    unsigned int azpSub = 0;\n    for(int i = aBegin, j = bBegin; i <= aEnd; i += BLOCK_SIZE, j += BLOCK_SIZE){\n        As[ty][tx] = A[i + ty * k + tx];\n        Bs[ty][tx] = W[j + ty * k + tx];\n        Wzp[ty][tx] = W_zp[i + ty * k + tx];\n\n        __syncthreads();\n\n        for(int k = 0; k < 32; k += 4){\n            unsigned int pack_val1 = reinterpret_cast<unsigned int*>(&(As[ty][k]))[0];\n            unsigned int pack_val2 = reinterpret_cast<unsigned int*>(&(Bs[tx][k]))[0];\n            unsigned int pack_val3 = reinterpret_cast<unsigned int*>(&(Wzp[ty][k]))[0];\n            cSub = __dp4a(pack_val1, pack_val2, cSub);\n            azpSub = __dp4a(pack_val1, pack_val3, azpSub);\n        }\n        __syncthreads();\n    }\n    \n    int cx = by * BLOCK_SIZE + ty;\n    int cy = bx * BLOCK_SIZE + tx;\n\n    cSub = cSub - Multi_w_zp[cx*n+cy] - azpSub + ZP_accu[cx*n+cy];\n    cSub = (cSub * integer) >> shift_val;\n\n    C[cx*n+cy] = (uint8_t)cSub;\n}",
        "gridDim": [
            8,
            8
        ],
        "blockDim": [
            32,
            32
        ]
    }
]